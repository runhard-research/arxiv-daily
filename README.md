# arXiv Daily Papers

_Last updated: 2026-01-07_

---

## Computer Vision
<!-- START:vision -->
_No papers found._
<!-- END:vision -->

## Large Language Models
<!-- START:llm -->
### STReasoner: Empowering LLMs for Spatio-Temporal Reasoning in Time Series via Spatial-Aware Reinforcement Learning
- **arXiv**: http://arxiv.org/abs/2601.03248v1
- **Summary**:
  - Spatio-temporal reasoning in time series involves the explicit synthesis of temporal dynamics, spatial dependencies, and textual context.
  - This capability is vital for high-stakes decision-making in systems such as traffic networks, power grids, and disease propagation.

### UltraLogic: Enhancing LLM Reasoning through Large-Scale Data Synthesis and Bipolar Float Reward
- **arXiv**: http://arxiv.org/abs/2601.03205v1
- **Summary**:
  - While Large Language Models (LLMs) have demonstrated significant potential in natural language processing , complex general-purpose reasoning requiring multi-step logic, planning, and verification remains a critical bottleneck.
  - Although Reinforcement Learning with Verifiable Rewards (RLVR) has succeeded in specific domains , the field lacks large-scale, high-quality, and difficulty-calibrated data for general reasoning.

### MemRL: Self-Evolving Agents via Runtime Reinforcement Learning on Episodic Memory
- **arXiv**: http://arxiv.org/abs/2601.03192v1
- **Summary**:
  - The hallmark of human intelligence is the ability to master new skills through Constructive Episodic Simulation-retrieving past experiences to synthesize solutions for novel tasks.
  - While Large Language Models possess strong reasoning capabilities, they struggle to emulate this self-evolution: fine-tuning is computationally expensive and prone to catastrophic forgetting, while existing memory-based methods rely on passive semantic matching that often retrieves noise.

### WebAnchor: Anchoring Agent Planning to Stabilize Long-Horizon Web Reasoning
- **arXiv**: http://arxiv.org/abs/2601.03164v1
- **Summary**:
  - Large Language Model(LLM)-based agents have shown strong capabilities in web information seeking, with reinforcement learning (RL) becoming a key optimization paradigm.
  - However, planning remains a bottleneck, as existing methods struggle with long-horizon strategies.

### Decoupling the Effect of Chain-of-Thought Reasoning: A Human Label Variation Perspective
- **arXiv**: http://arxiv.org/abs/2601.03154v1
- **Summary**:
  - Reasoning-tuned LLMs utilizing long Chain-of-Thought (CoT) excel at single-answer tasks, yet their ability to model Human Label Variation--which requires capturing probabilistic ambiguity rather than resolving it--remains underexplored.
  - We investigate this through systematic disentanglement experiments on distribution-based tasks, employing Cross-CoT experiments to isolate the effect of reasoning text from intrinsic model priors.

### One Sample to Rule Them All: Extreme Data Efficiency in RL Scaling
- **arXiv**: http://arxiv.org/abs/2601.03111v1
- **Summary**:
  - The reasoning ability of large language models (LLMs) can be unleashed with reinforcement learning (RL) (OpenAI, 2024; DeepSeek-AI et al., 2025a; Zeng et al., 2025).
  - The success of existing RL attempts in LLMs usually relies on high-quality samples of thousands or beyond.

### ATLAS: Adaptive Test-Time Latent Steering with External Verifiers for Enhancing LLMs Reasoning
- **arXiv**: http://arxiv.org/abs/2601.03093v1
- **Summary**:
  - Recent work on activation and latent steering has demonstrated that modifying internal representations can effectively guide large language models (LLMs) toward improved reasoning and efficiency without additional training.
  - However, most existing approaches rely on fixed steering policies and static intervention strengths, which limit their robustness across problem instances and often result in over- or under-steering.

<!-- END:llm -->

## Multimodal (MLLM)
<!-- START:mllm -->
### Text-Guided Layer Fusion Mitigates Hallucination in Multimodal LLMs
- **arXiv**: http://arxiv.org/abs/2601.03100v1
- **Summary**:
  - Multimodal large language models (MLLMs) typically rely on a single late-layer feature from a frozen vision encoder, leaving the encoder's rich hierarchy of visual cues under-utilized.
  - MLLMs still suffer from visually ungrounded hallucinations, often relying on language priors rather than image evidence.

### ReCCur: A Recursive Corner-Case Curation Framework for Robust Vision-Language Understanding in Open and Edge Scenarios
- **arXiv**: http://arxiv.org/abs/2601.03011v1
- **Summary**:
  - Corner cases are rare or extreme scenarios that drive real-world failures, but they are difficult to curate at scale: web data are noisy, labels are brittle, and edge deployments preclude large retraining.
  - We present ReCCur (Recursive Corner-Case Curation), a low-compute framework that converts noisy web imagery into auditable fine-grained labels via a multi-agent recursive pipeline.

<!-- END:mllm -->

## Vision + Robotics
<!-- START:vision_ro -->
### Text-Guided Layer Fusion Mitigates Hallucination in Multimodal LLMs
- **arXiv**: http://arxiv.org/abs/2601.03100v1
- **Summary**:
  - Multimodal large language models (MLLMs) typically rely on a single late-layer feature from a frozen vision encoder, leaving the encoder's rich hierarchy of visual cues under-utilized.
  - MLLMs still suffer from visually ungrounded hallucinations, often relying on language priors rather than image evidence.

### Motion Blur Robust Wheat Pest Damage Detection with Dynamic Fuzzy Feature Fusion
- **arXiv**: http://arxiv.org/abs/2601.03046v1
- **Summary**:
  - Motion blur caused by camera shake produces ghosting artifacts that substantially degrade edge side object detection.
  - Existing approaches either suppress blur as noise and lose discriminative structure, or apply full image restoration that increases latency and limits deployment on resource constrained devices.

### SOP: A Scalable Online Post-Training System for Vision-Language-Action Models
- **arXiv**: http://arxiv.org/abs/2601.03044v1
- **Summary**:
  - Vision-language-action (VLA) models achieve strong generalization through large-scale pre-training, but real-world deployment requires expert-level task proficiency in addition to broad generality.
  - Existing post-training approaches for VLA models are typically offline, single-robot, or task-specific, limiting effective on-policy adaptation and scalable learning from real-world interaction.

### PiDR: Physics-Informed Inertial Dead Reckoning for Autonomous Platforms
- **arXiv**: http://arxiv.org/abs/2601.03040v1
- **Summary**:
  - A fundamental requirement for full autonomy is the ability to sustain accurate navigation in the absence of external data, such as GNSS signals or visual information.
  - In these challenging environments, the platform must rely exclusively on inertial sensors, leading to pure inertial navigation.

### Learning to Act Robustly with View-Invariant Latent Actions
- **arXiv**: http://arxiv.org/abs/2601.02994v1
- **Summary**:
  - Vision-based robotic policies often struggle with even minor viewpoint changes, underscoring the need for view-invariant visual representations.
  - This challenge becomes more pronounced in real-world settings, where viewpoint variability is unavoidable and can significantly disrupt policy performance.

<!-- END:vision_ro -->
